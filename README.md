# reddit-tifu-bart-summarizer
Fineâ€‘tuned BART for abstractive summarization of Reddit TIFU posts
# Reddit TIFU Summarization with BART

A step-by-step Jupyter Notebook that demonstrates how to fine-tune a BART sequenceâ€‘toâ€‘sequence model on the Reddit â€œToday I F***ed Upâ€ (TIFU) dataset for abstractive summarization.

---

## ğŸ” Overview

This notebook will show you how to:

1. **Load & explore** the Reddit TIFU dataset viaÂ `datasets.load_dataset`  
2. **Preprocess** the text (tokenization, truncation) using a BART tokenizer  
3. **Configure & run** HuggingÂ Faceâ€™s `Seq2SeqTrainer`  
4. **Evaluate** your model with ROUGE metrics  
5. **Visualize** training curves with Matplotlib  
6. **Generate** sample summaries with a `transformers.pipeline`

---

## ğŸ“¦ Requirements

- PythonÂ 3.7+  
- ğŸ¤— Transformers  
- ğŸ¤— Datasets  
- ğŸ¤— Evaluate  
- Pandas  
- Matplotlib  
- HuggingÂ Face Hub CLI (for pushing your model)

Install with pip:

```bash
pip install transformers datasets evaluate pandas matplotlib huggingface_hub
